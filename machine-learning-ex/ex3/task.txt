Session 1:
1. run:
    % Load saved matrices from file
    load('ex3data1.mat');
    % The matrices X and y will now be in your MATLAB environment

2. run:
    m = size(X, 1);
    % Randomly select 100 data points to display
    rand_indices = randperm(m);
    sel = X(rand_indices(1:100), :);
    
    displayData(sel);

3. run:
    theta_t = [-2; -1; 1; 2];
    X_t = [ones(5,1) reshape(1:15,5,3)/10];
    y_t = ([1;0;1;0;1] >= 0.5);
    lambda_t = 3;

4. lrCostFunction.m:
   h_theta = sigmoid(X * theta);
    
    % Cost
    
    J = (1/m) * (((-1 * y') * log(h_theta)) - ((1-y') * log(1-h_theta))) + (lambda/(2*m)) * (sum(theta(2:end) .^ 2));
    
    temp = theta;
    temp(1) = 0;

    grad = ((1 / m) * X' * (h_theta - y)) + (lambda / m) * temp;

5. run:
    theta_t = [-2; -1; 1; 2];
    X_t = [ones(5,1) reshape(1:15,5,3)/10];
    y_t = ([1;0;1;0;1] >= 0.5);
    lambda_t = 3;
    [J, grad] = lrCostFunction(theta_t, X_t, y_t, lambda_t);
    
    fprintf('Cost: %f | Expected cost: 2.534819\n',J);
    fprintf('Gradients:\n'); fprintf('%f\n',grad);
    fprintf('Expected gradients:\n 0.146561\n -0.548558\n 0.724722\n 1.398003');
 
submit & complete task1

Session 2:
6. oneVsAll.m:
    
    initial_theta = zeros(n + 1, 1);
    options = optimset('GradObj', 'on', 'MaxIter', 50);
    
    for c=1:num_labels
        all_theta(c, :) = fmincg(@(t)(lrCostFunction(t, X, (y==c), lambda)), initial_theta, options);
    
    end
    % remember y (5000*1) is an array of labels i.e. it contains actual 
        % digit names (y==c) will return a vector with values 0 or 1. 1 at places where y==c 
        
        % 't' is passed as dummy parameter which is initialized with 'initial_theta' first
        % then subsequent values are choosen by fmincg [Note: Its not a builtin function like fminunc
        
        % fmincg will consider all training data having label c (1-10 note
        % 0 is mapped to 10) and find the optimal theta vector for it (Classifying white pixels with gray pixels). same
        % process is repeated for other classes

7. run:
    num_labels = 10; % 10 labels, from 1 to 10 
    lambda = 0.1;
    [all_theta] = oneVsAll(X, y, num_labels, lambda);

8. predictOnevsall.m:
    p-all= sigmoid(X * all_theta)
    [max_indx, p] = max(p_allt, [], 2);

9. run:
    pred = predictOneVsAll(all_theta, X);
    fprintf('\nTraining Set Accuracy: %f\n', mean(double(pred == y)) * 100);

    submit & 70% wrok is done.

Session 3:
10. run(load):
    load('ex3data1.mat');
    m = size(X, 1);
    
    % Randomly select 100 data points to display
    sel = randperm(size(X, 1));
    sel = sel(1:100);
    displayData(X(sel, :));
    
    % Load saved matrices from file
    load('ex3weights.mat'); 
    % Theta1 has size 25 x 401
    % Theta2 has size 10 x 26

11. 